{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic programming again: Implementing the Viterbi algorithm\n",
    "\n",
    "As discussed in class, finite-state automata can be made probabilistic by adding a weight to every transition arc.\n",
    "**Hidden Markov Models** (HMMs) provide an alternative format of specifying probabilistic FSAs.\n",
    "This unit presents an implementation of arguably the Viterbi algorithm for HMMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on HMMs\n",
    "\n",
    "The details of HMMs are covered in the lecture notes, but a brief reminder never hurts:\n",
    "\n",
    "1. The arcs between states are unlabeled, but have a probability that encodes how likely the automaton is to switch from one state to the other.\n",
    "These are the **transition probabilities**.\n",
    "1. In addition, each state has a table of **emission probabilities**, which tell us how likely it is to encounter a given symbol while the automaton is in this state.\n",
    "\n",
    "In this notebook, we will also assume that there is exactly one initial state.\n",
    "The initial state's emission probabilities are always 0.\n",
    "It's only purpose, then, is to provide transition probabilities to the other states.\n",
    "This gives us a basic starting point for the HMM.\n",
    "\n",
    "In addition, we will also assume that there is exactly one final state and that one can always transition from any state into the final state to stop there.\n",
    "This is just a technical trick that will make simplify some aspects of the implementation.\n",
    "\n",
    "Given a HMM, one often wants to know what the most likely sequence of states is for a given input.\n",
    "Just like the Levenshtein distance, this is a problem that cannot be solved with brute force.\n",
    "Suppose our HMM has only two states N (for noun) and V (for verb).\n",
    "Then a simple sentence like \"police police police police police\" already has `2 ** 5 = 32` different paths.\n",
    "In some applications like genome sequencing, the HMM might have hundreds of states and the string might be thousands of symbols long.\n",
    "Needless to say, `100 ** 1000` is way too big a number to compute the probability for each path from scratch.\n",
    "Instead, we use dynamic programming to compute the probabilities for subpaths, store these values, and reuse them to compute the values of longer paths.\n",
    "\n",
    "The rest of this notebook presupposes that you're already familiar with the Viterbi algorithm and its use of a table for computing probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic HMM implementation\n",
    "\n",
    "We start with a very simple class `hmm` for HMMs.\n",
    "It largely builds on our `fsa` class.\n",
    "Transmissions are passed in as a list of triples and then converted into a dictionary via `update`.\n",
    "The format is slightly different, though.\n",
    "The triples are assumed to follow the pattern `(source_state, goal_state, transition_probability)`.\n",
    "Similarly, the dictionary has a slightly different format that is easier to use with the Viterbi algorithm:\n",
    "\n",
    "```python\n",
    "{source_state: {goal_state: transition_probablity}}\n",
    "```\n",
    "\n",
    "We also pass in emissions as triples of the form `(state, symbol, emission_probability)`.\n",
    "The method `set_emit` is then used to construct a dictionary of the form\n",
    "\n",
    "```python\n",
    "{state: {symbol: emission_probability}}\n",
    "```\n",
    "\n",
    "We also add a variable `self.states` that keeps track of all the states that are not the initial state (by default `0`) or the final state (by default `-1`).\n",
    "This, too, will simplify some aspects of the Viterbi algorithm.\n",
    "\n",
    "Finally, we add a transition from every state to the final state.\n",
    "For convenience, we sets its probability to 1.\n",
    "This means that we do not discriminate between states as to whether they can occur at the very end of a state sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmm():\n",
    "    def __init__(self, start=0, final=-1, trans=[], emissions=[]):\n",
    "        self.start = start\n",
    "        self.final = -1\n",
    "        self.states = set()\n",
    "        self.trans = {}\n",
    "        for t in trans:\n",
    "            self.update(t)\n",
    "        self.emissions = {}\n",
    "        for e in emissions:\n",
    "            self.set_emit(e)\n",
    "        for state in self.states:\n",
    "            self.trans[state] = self.trans.get(state, {})\n",
    "            self.trans[state][final] = 1\n",
    "        \n",
    "        \n",
    "    def update(self, trans):\n",
    "        source, goal, prob = trans\n",
    "        self.trans[source] = self.trans.get(source, {})\n",
    "        self.trans[source][goal] = prob\n",
    "        # add new states to hmm's set of states\n",
    "        if source != self.start:\n",
    "            self.states.add(source)\n",
    "        if goal != self.final:\n",
    "            self.states.add(goal)\n",
    "        \n",
    "        \n",
    "    def set_emit(self, e):\n",
    "        state, word, prob = e\n",
    "        self.emissions[state] = self.emissions.get(state, {})\n",
    "        self.emissions[state][word] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "police = hmm(trans=[(0, \"N\", .8),\n",
    "                    (0, \"V\", .2),\n",
    "                    (\"N\", \"N\", .3),\n",
    "                    (\"N\", \"V\", .7),\n",
    "                    (\"V\", \"N\", .9),\n",
    "                    (\"V\", \"V\", .1)],\n",
    "            emissions=[(\"V\", \"police\", 1),\n",
    "                       (\"N\", \"police\", 1)])\n",
    "\n",
    "print(\"Transition probabilities:\")\n",
    "pprint(police.trans, width=1)\n",
    "\n",
    "print(\"Emission probabilities:\")\n",
    "pprint(police.emissions, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketching out the Viterbi algorithm\n",
    "\n",
    "The central tool of the Viterbi algorithm is the table in which it keeps track of probabilities.\n",
    "The table contains a column for each position in the input, and a row for each state of the HMM (excluding the inital state and the final state).\n",
    "The algorithm fills in the cells of this table column-by-column from left to right.\n",
    "In order to compute the value of a cell, one needs easy access to all the cells of the previous column.\n",
    "\n",
    "Whatever data structure we use to implement this table in Python, it needs to be something that gives us easy access to each column.\n",
    "A natural choice is a dictionary where each key is a position in the string and the value is the corresponding column in the Viterbi table.\n",
    "Each column, in term, is a dictionary where each key indicates a row, i.e. the value for a specific state.\n",
    "\n",
    "For instance, the example HMM above would use the following dictionary for the input `[\"police\", \"police\", \"police\"]`:\n",
    "\n",
    "```python\n",
    "{0: {\"N\": \"value in column 0 for N\",\n",
    "     \"V\": \"value in column 0 for V\"}\n",
    " 1: {\"N\": \"value in column 1 for N\",\n",
    "     \"V\": \"value in column 1 for V\"},\n",
    " 2: {\"N\": \"value in column 2 for N\",\n",
    "     \"V\": \"value in column 2 for V\"}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly adding the code to our class, let's first sketch a function that could construct such a table for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(sentence, states):\n",
    "    # initialize empty dictionary\n",
    "    matrix = {}\n",
    "    # construct matrix column by column\n",
    "    for pos in range(len(sentence)):\n",
    "        # initialize empty column\n",
    "        matrix[pos] = {}\n",
    "        # add cell for each row in the current column\n",
    "        for state in states:\n",
    "            matrix[pos][state] = \"some_value\"\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(matrix([\"police\", \"police\", \"police\"], [\"N\", \"V\"]), width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, this looks pretty much like what we had in mind.\n",
    "The next step is to figure out what we should put in those cells.\n",
    "Remember that the Viterbi algorithm actually stores two values in each cell:\n",
    "\n",
    "1. the highest possible probability value, and\n",
    "1. a backpointer to a cell in the previous column that the probability value was obtained from.\n",
    "\n",
    "In rare occassions there might actually be multiple cells in the previous column that can produce the highest probability value.\n",
    "For simplicity, we will ignore this case for now.\n",
    "Either way, though, we need to store two values per cell.\n",
    "The simplest option is, once again, a dictionary, with a key `\"prob\"` for the probability and a key `\"from\"` for the backpointer.\n",
    "The value of `\"from\"` is the state that represents the row of the cell that the backpointer picks out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(sentence, states):\n",
    "    matrix = {}\n",
    "    for pos in range(len(sentence)):\n",
    "        matrix[pos] = {}\n",
    "        for state in states:\n",
    "            # every cell is a dictionary with two values\n",
    "            matrix[pos][state] = {\"prob\": \"some_probability\", \"from\": \"some_state\"}\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(matrix([\"police\", \"police\", \"police\"], [\"N\", \"V\"]), width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the code so far doesn't get us any closer to actually determining these values.\n",
    "As the next step, let's expand the `matrix` function to a skeleton for the Viterbi algorithm.\n",
    "We will intersperse the construction of the matrix with steps to fill each value with appropriate values.\n",
    "However, we will still leave largely open how these values are computed.\n",
    "The only thing we know is that they can only depend on the factors that are considered by the Viterbi algorithm:\n",
    "\n",
    "1. the symbol at the current position of the input, and\n",
    "1. the state, and\n",
    "1. the preceding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(hmm, sentence):\n",
    "    matrix = {}\n",
    "    for pos in range(len(sentence)):\n",
    "        matrix[pos] = {}\n",
    "        # store previous column for later use ({} if non-existent)\n",
    "        previous_column = matrix.get(pos-1, {})\n",
    "        for state in states:\n",
    "            # initialize empty cell\n",
    "            matrix[pos][state] = {}\n",
    "            # use cell as a shorthand\n",
    "            cell = matrix[pos][state]\n",
    "            # set values for cell\n",
    "            cell[\"prob\"], cell[\"from\"] = some_mystery_function(hmm, sentence[pos], state, previous_column)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Believe it or not, this is actually the Viterbi algorithm in a nutshell.\n",
    "Well, almost.\n",
    "Of course we still have to figure out what the mystery function is.\n",
    "Whatever it is, we want the function to return a pair of values.\n",
    "The first one will be stored under the key `\"prob\"`, the second one under the key `\"from\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal cell in the previous row\n",
    "\n",
    "The mystery function has the job of computing the probability value for the cell and the appropriate backpointer.\n",
    "The Viterbi algorithm does this as follows for our example HMM:\n",
    "\n",
    "1. Suppose we are in column `3` and state `N`.\n",
    "1. The previous column is column `2`.\n",
    "1. Each cell in column `2` belongs to a specific state, `V` or `N`.\n",
    "1. For each state, we look up the probability of transitioning to `N`.\n",
    "   From `N` to `N` it is `.3`, from `V` to `N` it is `.9`.\n",
    "1. The transition probability is multiplied with the probability in the corresponding cell of the previous row.\n",
    "   So if column 2 is `{'N': {\"prob\": .2, \"from\": 'V}, 'V': {\"prob\": .35, \"from\": 'N'}`, then the relevant multiplications are\n",
    "   - from `N` to `N`: `.3 * .2`\n",
    "   - from `V` to `N`: `.9 * .35`.\n",
    "1. The probability for the current cell is based on the larger one of the two, i.e. `.9 * .35`, which is `.315`.\n",
    "   We then multiply this value with the emission probability.\n",
    "1. Since this probability is based on the values for `V`, the backpointer is set to `V`.\n",
    "\n",
    "In sum, we have to iterate over all the cells in the previous column and check which one gives us the highest probability.\n",
    "We then compute the overall probability based on that and the emission probability.\n",
    "Let us focus only on the first step for now: finding the optimal cell in the previous row.\n",
    "\n",
    "There's many ways of doing this.\n",
    "We'll look at two different options here.\n",
    "For both of them, it will be useful to have a helper function to quickly get the relevant transition probability in a safe manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tprob(hmm, source, goal):\n",
    "    return hmm.trans.get(source, {}).get(goal, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function looks up the probability for going from state `source` to state `goal` in some HMM.\n",
    "If for some reason this probability cannot be found, the function returns 0 as a safe default.\n",
    "Simple enough, so let's move on to the first implementation for calculating the cell value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexed_max(hmm, state, matrix_column):\n",
    "    # inititalize backpointer and highest probability\n",
    "    backpointer = None\n",
    "    optimal = 0\n",
    "    # iterate over cells in column\n",
    "    for cell_state, cell_values in matrix_column.items():\n",
    "        # reminder: each column is a dictionary of the form\n",
    "        # {state: {\"prob\": some_value, \"from\": some_vale}}\n",
    "        cell_state_prob = cell_values[\"prob\"]\n",
    "        # prob = cell probability * transition probability\n",
    "        prob = cell_state_prob * tprob(hmm, cell_state, state)\n",
    "        # if we found something more likely, update optimal and backpointer\n",
    "        if prob > optimal:\n",
    "            optimal = prob\n",
    "            backpointer = cell_state\n",
    "    # loop over: optimal and backpointer are set to best possible values\n",
    "    # we return a pair\n",
    "    return (optimal, backpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `indexed_max` function iterates over all cells of the previous column and keeps updating the values for `optimal` and `backpointer` whenever it comes across a cell that offers a higher probability value than whatever is currently stored in `optimal`.\n",
    "\n",
    "With our example above, Python would go through the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state is 'N'\n",
    "# column 2 is {'N': {\"prob\": .2, \"from\": 'V'},\n",
    "#              'V': {\"prob\": .35, \"from\": 'N'}\n",
    "\n",
    "# initialization\n",
    "backpointer = None\n",
    "optimal = 0\n",
    "\n",
    "# start for-loop\n",
    "cell_state = 'V'\n",
    "cell_values = {\"prob:\" .35, \"from\": 'N'}\n",
    "cell_state_prob = .35\n",
    "prob = .35 * tprob(hmm, 'N', 'N')  # .35 * .9\n",
    "\n",
    "# new values are bigger\n",
    "backpointer = 'V'\n",
    "optimal = 0.315\n",
    "\n",
    "# continue for-loop with next cell\n",
    "cell_state = 'N'\n",
    "cell_values = {\"prob:\" .2, \"from\": 'V'}\n",
    "cell_state_prob = .2\n",
    "prob = .2 * tprob(hmm, 'N', 'N')  # .2 * .3\n",
    "\n",
    "# new values aren't bigger, keep backpointer and optimal the same\n",
    "\n",
    "# for-loop done, return (optimal, backpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `indexed_max` doesn't return the final probability for the cell yet at it does not factor in emission probabilities.\n",
    "This will have to be handled by a different function later on.\n",
    "\n",
    "Even though `indexed_max` is pretty simple, it may seem a little cluttered.\n",
    "Alternatively, we could use list comprehensions and Python's `max` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_max(hmm, state, matrix_column):\n",
    "    options = [(cell_state,\n",
    "                cell_values[\"prob\"] * tprob(hmm, cell_state, state))\n",
    "               for cell_state, cell_values in matrix_column.items()]\n",
    "    return max(options, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function first constructs a list of `(state, probability)`-pairs and then uses `max` to extract the pair with the highest probability.\n",
    "The code `key=lambda x: x[1]` tells `max` to only pay attention to the second component of each pair.\n",
    "\n",
    "Python proceeds quite a bit differently with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state is 'N'\n",
    "# column 2 is {'N': {\"prob\": .2, \"from\": 'V'},\n",
    "#              'V': {\"prob\": .35, \"from\": 'N'}\n",
    "\n",
    "# construct list\n",
    "options = [('N', 0.06), ('V', 0.315)]\n",
    "\n",
    "# return max based on second component of pairs\n",
    "return ('V', 0.315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it might be more efficient since it involves fewer steps.\n",
    "But in facts, this is less efficient because it requires the construction of a list.\n",
    "Whereas `indexed_max` only iterates over existing data structures and stores small intermediate values in two variables, `list_max` has to construct a new list with as many items as there are states.\n",
    "As HMM can easily contain thousands of states, constructing this list from scratch for every new cell is very wasteful.\n",
    "Hence we will use `indexed_max` in this notebook even though it isn't as elegant as `list_max`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding emission probabilities\n",
    "\n",
    "With `indexed_max` we only get a backpointer to a cell and the basic probability obtained by multiplying that cell's probability with the transition probability.\n",
    "We still need to factor in the transmission probability.\n",
    "That is easily done with a separate function `cell_value` that calls `indexed_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_value(hmm, word, state, matrix_column):\n",
    "    optimal, backpointer = indexed_max(hmm, state, matrix_column)\n",
    "    optimal *= hmm.emissions.get(state, {}).get(word, 0)\n",
    "    return (optimal, backpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function first gets the values for `optimal` and `backpointer` from `indexed_max`, and then multiplies `optimal` by the emission probability for the current word and state according to the HMM.\n",
    "If there is no emission probabilty, `0` is used as a default.\n",
    "\n",
    "All we need to do now is to got back to the definition of the `viterbi` function and replace `some_mystery_function` with `cell_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(hmm, sentence):\n",
    "    matrix = {}\n",
    "    for pos in range(len(sentence)):\n",
    "        matrix[pos] = {}\n",
    "        # store previous column for later use ({} if non-existent)\n",
    "        previous_column = matrix.get(pos-1, {})\n",
    "        for state in states:\n",
    "            # initialize empty cell\n",
    "            matrix[pos][state] = {}\n",
    "            # use cell as a shorthand\n",
    "            cell = matrix[pos][state]\n",
    "            # set values for cell\n",
    "            cell[\"prob\"], cell[\"from\"] = cell_value(hmm, sentence[pos], state, previous_column)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alas, this won't quite work because of a major oversight on our part.\n",
    "The very first column of the table doesn't have a preceding column.\n",
    "So `previous_column` will be set to `{}`.\n",
    "Now consider what happens when Python runs `cell_value(hmm, sentence[0], state, {})`.\n",
    "According to the definition of `cell_value`, we immediately call `indexed_max(hmm, state, {})`.\n",
    "This causes `indexed_max` to return `(0, None)`.\n",
    "That's because `{}` contains no items to iterate over, so we never get to overwrite the default values of `optimal = 0` and `backpointer = None`.\n",
    "As every column depends on the values of the previous column, screwing up the first column means screwing up the whole table!\n",
    "\n",
    "In order to fix this, we have to tell `cell_value` that it should computed the values of the first column differently.\n",
    "For the first column, the backpointer should always refer to the HMM's initial state, and the probability is just the transition probability from the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_value(hmm, word, state, matrix_column):\n",
    "    if not matrix_column:\n",
    "        # we're working on the first column!\n",
    "        optimal = tprob(hmm.start, state)\n",
    "        backpointer = hmm.start\n",
    "    else:\n",
    "        optimal, backpointer = indexed_max(hmm, state, matrix_column)\n",
    "    optimal *= hmm.emissions.get(state, {}).get(word, 0)\n",
    "    return (optimal, backpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this modified function, we finally have a working implementation of the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to class methods\n",
    "\n",
    "We can now add all the functions defined above as methods to the `hmm` class.\n",
    "Since many of these functions are just helper methods that aren't meant to be directly used by the user, we add an underscore `_` in front of their name.\n",
    "This is just a naming convention and does not change at all how they're treated by Python.\n",
    "Also keep in mind that we have to add `self` as the first argument to each function.\n",
    "Often this replaces the argument `hmm` that we used in the function definitions above.\n",
    "This also means that code like `hmm.emissions` is replaced by `self.emissions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmm():\n",
    "    def __init__(self, start=0, final=-1, trans=[], emissions=[]):\n",
    "        self.start = start\n",
    "        self.final = -1\n",
    "        self.states = set()\n",
    "        self.trans = {}\n",
    "        for t in trans:\n",
    "            self.update(t)\n",
    "        if isinstance(emissions, dict):\n",
    "            self.emissions = emissions\n",
    "        else:\n",
    "            self.emissions = {}\n",
    "            for e in emissions:\n",
    "                self.set_emit(e)\n",
    "        for state in self.states:\n",
    "            self.trans[state] = self.trans.get(state, {})\n",
    "            self.trans[state][final] = 1\n",
    "        \n",
    "        \n",
    "    def update(self, trans):\n",
    "        source, goal, prob = trans\n",
    "        self.trans[source] = self.trans.get(source, {})\n",
    "        self.trans[source][goal] = prob\n",
    "        # add new states to hmm's set of states\n",
    "        if source != self.start:\n",
    "            self.states.add(source)\n",
    "        if goal != self.final:\n",
    "            self.states.add(goal)\n",
    "        \n",
    "        \n",
    "    def set_emit(self, e):\n",
    "        state, word, prob = e\n",
    "        self.emissions[state] = self.emissions.get(state, {})\n",
    "        self.emissions[state][word] = prob\n",
    "        \n",
    "        \n",
    "    def _prob(self, source, goal):\n",
    "        return self.trans.get(source, {}).get(goal, 0)\n",
    "    \n",
    "    \n",
    "    def _indexed_max(self, state, matrix_column):\n",
    "        backpointer = None\n",
    "        optimal = 0\n",
    "        for cell_state, cell_values in matrix_column.items():\n",
    "            cell_state_prob = cell_values[\"prob\"]\n",
    "            prob = cell_state_prob * self._prob(cell_state, state)\n",
    "            if prob > optimal:\n",
    "                optimal = prob\n",
    "                backpointer = cell_state\n",
    "        return (optimal, backpointer)\n",
    "            \n",
    "    \n",
    "    def _cell_value(self, word, state, matrix_column):\n",
    "        if not matrix_column:\n",
    "            # no matrix_column exists, use default values for column 1\n",
    "            optimal = self._prob(self.start, state)\n",
    "            backpointer = self.start\n",
    "        else:\n",
    "            optimal, backpointer = self._indexed_max(state, matrix_column)\n",
    "        optimal *= self.emissions.get(state, {}).get(word, 0)\n",
    "        return (optimal, backpointer)\n",
    "        \n",
    "        \n",
    "    def viterbi(self, sentence):\n",
    "        # compute matrix column by column;\n",
    "        matrix = dict()\n",
    "        for pos in range(len(sentence)):\n",
    "            # start new column\n",
    "            matrix[pos] = dict()\n",
    "            # and get previous column, if it exists\n",
    "            previous_column = matrix.get(pos-1, dict())\n",
    "            # for each column, fill in the state rows\n",
    "            for state in self.states:\n",
    "                # create empty cell\n",
    "                matrix[pos][state] = dict()\n",
    "                cell = matrix[pos][state]\n",
    "                # and compute its probability and backpointer\n",
    "                cell[\"prob\"], cell[\"from\"] = self._cell_value(sentence[pos], state, previous_column)\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally see our code in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "police = hmm(trans=[(0, \"N\", .8),\n",
    "                    (0, \"V\", .2),\n",
    "                    (\"N\", \"N\", .3),\n",
    "                    (\"N\", \"V\", .7),\n",
    "                    (\"V\", \"N\", .9),\n",
    "                    (\"V\", \"V\", .1)],\n",
    "             emissions=[(\"V\", \"police\", 1),\n",
    "                        (\"N\", \"police\", 1)])\n",
    "\n",
    "# test sentence: [police [that the police does police]] does police the police]\n",
    "ambiguous = [\"police\"] * 5\n",
    "print(ambiguous)\n",
    "\n",
    "pprint(police.viterbi(ambiguous), width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, that's the kind of table we need for the Viterbi algorithm.\n",
    "But its still not the actual output.\n",
    "We want to know the most likely state assignment for the sentence.\n",
    "For this, we have to add another method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best path\n",
    "\n",
    "Given a Viterbi table, we can find the best path in two steps:\n",
    "\n",
    "1. In the last column, find the cell with the highest probability value.\n",
    "1. Follow the backpointers all the way to the start.\n",
    "\n",
    "The function below does just that, but in a somewhat clever fashion.\n",
    "Pay close attention to the use of `indexed_max`, and try to figure out how it picks out the optimal cell in the last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestpath(hmm, matrix, sentence):\n",
    "    length = len(sentence)\n",
    "    pick = hmm._indexed_max(hmm.final, matrix[length - 1])[1]\n",
    "    path = [pick]\n",
    "    for pos in reversed(range(1, length)):\n",
    "        pick = matrix[pos][pick][\"from\"]\n",
    "        path.append(pick)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got it?\n",
    "No?\n",
    "Alright, let's go through it:\n",
    "\n",
    "1. `matrix[length - 1]` gives us the last column of the Viterbi table.\n",
    "1. Remember that every state has a transition to the final state, with a probability of one.\n",
    "1. Usually, `hmm._indexed_max(hmm.final, matrix[length - 1])` would pick the best cell based on its stored probability and the transition probability.\n",
    "   But since all states have the same transition probability of 1 to the final state, only the stored probability matters.\n",
    "1. Consequently, `hmm._indexed_max` returns the cell in the last row with the highest probability value.\n",
    "\n",
    "Once that cell has been found, we make it the first element of our variable `path`.\n",
    "At this point, we only have to follow the backpointers.\n",
    "To do this, we have to look up the value of the backpointer in the last but one column, get the backpointer there and check the corresponding cell in the last but two column, and so on.\n",
    "This is a simple for loop with `range`, except that we use `reversed`:\n",
    "\n",
    "1. `range(1, length)` goes from `1` to whatever the value of `length` is.\n",
    "1. `reversed` switches the ordering; for instance, (1, 2, 3, 4) becomes (4, 3, 2, 1).\n",
    "\n",
    "So we start with the last column, look at the value of `pick` there (i.e. the cell with the highest probability), and get the backpointer stored under the key `\"from\"`.\n",
    "This is the new value for `pick`.\n",
    "It gets added to `path`, then we look at the last but one column, check the cell indicated by the backpointer there, get its backpointer via `\"from\"`, make that the new pick, add it to path, move on to the column before that, and so on.\n",
    "Notice that we do not check the very first column (`range` starts at `1`) because all the backpointers there always point to the initial state, which is of no interest to us.\n",
    "\n",
    "We modify `bestpath` so that it intersperses the elements of path with the elements of the input, giving us a nice annotation of the whole input.\n",
    "Keep in mind that `path` starts with the last state and then proceeds towards the first, so we have to reverse its order when interspersing it with the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestpath(hmm, matrix, sentence):\n",
    "    length = len(sentence)\n",
    "    pick = hmm._indexed_max(hmm.final, matrix[length - 1])[1]\n",
    "    path = [pick]\n",
    "    for pos in reversed(range(1, length)):\n",
    "        pick = matrix[pos][pick][\"from\"]\n",
    "        path.append(pick)\n",
    "    return [(sentence[pos], path[-(pos+1)]) for pos in range(length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final modification: if at any point `pick` is set to `None`, we have run into a pathological case where, for some reason, no optimal path exists at all.\n",
    "This can happen if the input contains a symbol for which every state has an emission probability of `0`.\n",
    "Since there is no optimal path, we should return an empty list instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestpath(hmm, matrix, sentence):\n",
    "    length = len(sentence)\n",
    "    pick = hmm._indexed_max(hmm.final, matrix[length - 1])[1]\n",
    "    path = [pick]\n",
    "    for pos in reversed(range(1, length)):\n",
    "        if pick is None:\n",
    "            return []\n",
    "        pick = matrix[pos][pick][\"from\"]\n",
    "        path.append(pick)\n",
    "    return [(sentence[pos], path[-(pos+1)]) for pos in range(length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: the `hmm` class\n",
    "\n",
    "The `bestpath` function is our last addition to the `hmm` class.\n",
    "As a convenient shorthand, we define the method `parse` that first constructs a Viterbi table and then constructs the best path from that.\n",
    "We also add docstrings to all our methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmm():\n",
    "    def __init__(self, start=0, final=-1, trans=[], emissions=[]):\n",
    "        \"\"\"Class for Hidden Markov models.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        start: int or string\n",
    "            name of the unique initial state\n",
    "            default: 0\n",
    "        final: int or string\n",
    "            name of the unique final state\n",
    "            default: -1\n",
    "        transitions: list\n",
    "            list of transition tuples of the form (source, goal, probability)\n",
    "            default: empty list\n",
    "        emissions: list\n",
    "            list of emission tuples of the form (state, word, probability)\n",
    "            \n",
    "        Other attributes\n",
    "        ----------------\n",
    "        trans: dict\n",
    "            dictionary of transitions; use the format {source: {goal: probability}}\n",
    "        states: set\n",
    "            set of states, excluding initial and final\n",
    "        \"\"\"\n",
    "        self.start = start\n",
    "        self.final = -1\n",
    "        self.states = set()\n",
    "        self.trans = {}\n",
    "        for t in trans:\n",
    "            self.update(t)\n",
    "        if isinstance(emissions, dict):\n",
    "            self.emissions = emissions\n",
    "        else:\n",
    "            self.emissions = {}\n",
    "            for e in emissions:\n",
    "                self.set_emit(e)\n",
    "        for state in self.states:\n",
    "            self.trans[state] = self.trans.get(state, {})\n",
    "            self.trans[state][final] = 1\n",
    "        \n",
    "        \n",
    "    def update(self, trans):\n",
    "        \"\"\"Convert transmission triple to entry in transition dictionary.\"\"\"\n",
    "        source, goal, prob = trans\n",
    "        self.trans[source] = self.trans.get(source, {})\n",
    "        self.trans[source][goal] = prob\n",
    "        # add new states to hmm's set of states\n",
    "        if source != self.start:\n",
    "            self.states.add(source)\n",
    "        if goal != self.final:\n",
    "            self.states.add(goal)\n",
    "        \n",
    "        \n",
    "    def set_emit(self, e):\n",
    "        \"\"\"Convert emission triple to entry in emission dictionary.\"\"\"\n",
    "        state, word, prob = e\n",
    "        self.emissions[state] = self.emissions.get(state, {})\n",
    "        self.emissions[state][word] = prob\n",
    "        \n",
    "        \n",
    "    def _prob(self, source, goal):\n",
    "        \"\"\"Retrieve transition probability from source to goal.\"\"\"\n",
    "        return self.trans.get(source, {}).get(goal, 0)\n",
    "    \n",
    "    \n",
    "    def _indexed_max(self, state, matrix_column):\n",
    "        \"\"\"Find highest probability value and the cell it is derived from.\"\"\"\n",
    "        backpointer = None\n",
    "        optimal = 0\n",
    "        for cell_state, cell_values in matrix_column.items():\n",
    "            cell_state_prob = cell_values[\"prob\"]\n",
    "            prob = cell_state_prob * self._prob(cell_state, state)\n",
    "            if prob > optimal:\n",
    "                optimal = prob\n",
    "                backpointer = cell_state\n",
    "        return (optimal, backpointer)\n",
    "            \n",
    "    \n",
    "    def _cell_value(self, word, state, matrix_column):\n",
    "        \"\"\"Compute the value of a Viterbi cell.\"\"\"\n",
    "        if not matrix_column:\n",
    "            # no matrix_column exists, use default values for column 1\n",
    "            optimal = self._prob(self.start, state)\n",
    "            backpointer = self.start\n",
    "        else:\n",
    "            optimal, backpointer = self._indexed_max(state, matrix_column)\n",
    "        optimal *= self.emissions.get(state, {}).get(word, 0)\n",
    "        return (optimal, backpointer)\n",
    "        \n",
    "        \n",
    "    def viterbi(self, sentence):\n",
    "        \"\"\"Construct a Viterbi table with all cells filled.\"\"\"\n",
    "        # compute matrix column by column;\n",
    "        matrix = dict()\n",
    "        for pos in range(len(sentence)):\n",
    "            # start new column\n",
    "            matrix[pos] = dict()\n",
    "            # and get previous column, if it exists\n",
    "            previous_column = matrix.get(pos-1, dict())\n",
    "            # for each column, fill in the state rows\n",
    "            for state in self.states:\n",
    "                # create empty cell\n",
    "                matrix[pos][state] = dict()\n",
    "                cell = matrix[pos][state]\n",
    "                # and compute its probability and backpointer\n",
    "                cell[\"prob\"], cell[\"from\"] = self._cell_value(sentence[pos], state, previous_column)\n",
    "        return matrix\n",
    "    \n",
    "    \n",
    "    def _bestpath(self, matrix, sentence):\n",
    "        \"\"\"Find the best path through a Viterbi table.\"\"\"\n",
    "        length = len(sentence)\n",
    "        pick = self._indexed_max(self.final, matrix[length - 1])[1]\n",
    "        path = [pick]\n",
    "        for pos in reversed(range(1, length)):\n",
    "            if pick is None:\n",
    "                return []\n",
    "            pick = matrix[pos][pick][\"from\"]\n",
    "            path.append(pick)\n",
    "        return [(sentence[pos], path[-(pos + 1)]) for pos in range(length)]\n",
    "    \n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        \"\"\"Annotate the input with the most likely state assignment.\"\"\"\n",
    "        matrix = self.viterbi(sentence)\n",
    "        return self._bestpath(matrix, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "police = hmm(trans=[(0, \"N\", .8),\n",
    "                    (0, \"V\", .2),\n",
    "                    (\"N\", \"N\", .3),\n",
    "                    (\"N\", \"V\", .7),\n",
    "                    (\"V\", \"N\", .9),\n",
    "                    (\"V\", \"V\", .1)],\n",
    "             emissions=[(\"V\", \"police\", 1),\n",
    "                        (\"N\", \"police\", 1)])\n",
    "\n",
    "# test sentence: [police [that the police does police]] does police the police]\n",
    "ambiguous = [\"police\"] * 5\n",
    "print(ambiguous)\n",
    "pprint(police.viterbi(ambiguous), width=1)\n",
    "print(police.parse(ambiguous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a ridiculously challenging example with 100,000 words;\n",
    "# look how fast this still is!!!\n",
    "super_ambiguous = [\"police\"] * (10 ** 5)\n",
    "police.parse(super_ambiguous)\n",
    ";  # hide output, it takes longer to print than to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's quite a bit of code.\n",
    "You probably would have found this to be a very challenging homework assignment.\n",
    "But by proceeding step by step, even complex algorithms can be broken done into simple functions/methods that are then combined to yield the desired result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullet point summary\n",
    "\n",
    "- The Viterbi algorithm has three key components:\n",
    "    1. a table where columns represent positions in the input and rows states in the automaton\n",
    "    1. a mechanism for computing the optimal probability for a cell based on the cells in the preceding column\n",
    "    1. a mechanism for computing the optimal path from the backpointers in the table\n",
    "- The table can be implemented as a dictionary of the form\n",
    "\n",
    "```python\n",
    "{column_number: {state: {probability: some_value, backpointer: some_value}}}\n",
    "```\n",
    "\n",
    "- The hardest part is determining a cell's value.\n",
    "  This requires iterating over all cells in the previous column to determine which one leads to the highest probability value.\n",
    "  \n",
    "- Once the table is filled in, the optimal state assignment is found by picking the cell with highest probability in the last column and following the backpointers all the way to column 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
