{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with syntactic grammars\n",
    "\n",
    "Our models so far have all assumed that strings are indeed just that, strings.\n",
    "True, we tokenized strings to break them down into lists of words, and we occassionally added some hidden information such as parts of speech or morphological information like *stem* and *affix*.\n",
    "But at no point did we move beyond the idea that words and sentences are possibly more than linear sequences.\n",
    "However, that's exactly what linguists have figured out a long time ago for sentences: a sentence isn't just a sequence of words like beads on a string, but contains a lot of hidden structure.\n",
    "A sentence is more like a molecule, with the words as its atoms.\n",
    "\n",
    "This shift from strings to trees makes things a lot harder to implement.\n",
    "How does one represent these \"sentence molecules\", what is the right data structure, how can it be traversed and manipulated?\n",
    "And most importantly, how can we automatically get the structures just from the linear string?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Phrase structure grammars\n",
    "\n",
    "Let's have a quick linguistics recap for sentence structure.\n",
    "Linguists commonly use **phrase structure grammars** to describe the set of possible sentence structures in a language.\n",
    "Phrase structure grammars assume that sentence structures are trees.\n",
    "Just like prefix trees, they have a single **root** at the very top, and each node has 0 or more **daughter** nodes below it.\n",
    "A phrase structure grammar then is a finite set of **rewrite rules** that describe what daughters a node may have.\n",
    "\n",
    "Each rule is of the form `X -> daughter1 daughter2 daughter3...`.\n",
    "For instance, `S -> NP VP` tells us that a sentence (`S`) can be split into an `NP` and a `VP`.\n",
    "The former is the first daughter of the `S`-node in the tree, the second daughter is the latter.\n",
    "If we also add the rules `NP -> 'everybody'` and `VP -> 'snored'`, then we can already assign a structure to the simple sentence *everybody snored*:\n",
    "\n",
    "```\n",
    "       S\n",
    "      / \\\n",
    "     /   \\\n",
    "    /     \\\n",
    "   /       \\\n",
    " NP        VP\n",
    " |          |\n",
    "everybody  snored\n",
    "```\n",
    "\n",
    "We can represent this tree as a single string by using **labeled bracketing**:\n",
    "\n",
    "```\n",
    "(S (NP everybody) (VP snored) )\n",
    "```\n",
    "\n",
    "Right now our toy grammar contains only three rules.\n",
    "\n",
    "```\n",
    "S -> NP VP\n",
    "NP -> 'everybody'\n",
    "VP -> 'snored'\n",
    "```\n",
    "\n",
    "But of course we can add more rules to analyze more sentences than just *everybody snored*.\n",
    "\n",
    "```\n",
    "S -> NP VP\n",
    "S -> Aux NP V\n",
    "NP -> 'everybody'\n",
    "NP -> 'nobody'\n",
    "VP -> 'snored'\n",
    "Aux -> 'did'\n",
    "V -> 'snore'\n",
    "```\n",
    "\n",
    "This grammar has multiple rules for `S` and `NP`.\n",
    "Each one of these rules describes a valid configuration.\n",
    "So instead of `NP VP`, a sentence may also consist of `Aux NP V`, e.g. in *Did everybody snore*.\n",
    "\n",
    "For simplicity, rules with the same symbol on the left-hand side are often written on a single line, with the different options separated by `|` (the **pipe**).\n",
    "\n",
    "```\n",
    "S -> NP VP | Aux NP V\n",
    "NP -> 'everybody' | 'nobody'\n",
    "VP -> 'snored'\n",
    "Aux -> 'did'\n",
    "V -> 'snore'\n",
    "```\n",
    "\n",
    "You might have also noticed that words are flanked by quotes, whereas symbols like `S` and `NP` are not.\n",
    "While it may seem innocuous, it indicates an important distinction.\n",
    "Symbols like `S` and `NP` are **non-terminals**, which means that they cannot occur in the pronounced sentence.\n",
    "All symbols that appear on the left-hand side of a rule are non-terminals.\n",
    "The things that do appear in the string are called **terminals**, and they must never occur on the left hand-side of a rule.\n",
    "The quotes indicate the difference between terminals (with quotes) and non-terminals (no quotes).\n",
    "\n",
    "Alright, that's all nice and dandy, but it doesn't get us any closer to doing syntax in Python.\n",
    "Well, actually, it does, because Python's `nltk` package comes with tools that build directly on this way of defining phrase structure grammars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase structure grammars in `nltk`\n",
    "\n",
    "Consider once more our initial toy grammar.\n",
    "\n",
    "```\n",
    "S -> NP VP\n",
    "NP -> 'everybody'\n",
    "VP -> 'snored'\n",
    "```\n",
    "\n",
    "We can directly use this with `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "toy_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> 'everybody'\n",
    "VP -> 'snored'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a grammar `toy_grammar` that contains the specified rewrite rules.\n",
    "\n",
    "Let's look quickly at the name of the `nltk` function that allows us to do this: `nltk.CFG.fromstring`.\n",
    "That it starts with `nltk` is not surprising, after all it's a function of the `nltk` package.\n",
    "The `fromstring` part is also self-explanatory; we define the grammar as a string and pass that string to the function.\n",
    "But what does CFG mean?\n",
    "\n",
    "CFG is short for context-free grammar.\n",
    "From a mathematical perspective, phrase structure grammars and context-free grammars are the same thing.\n",
    "But phrase structure grammars are context-free grammars with a specific intended application.\n",
    "Phrase structure grammars are context-free grammars that are only meant to describe the structure of linguistic sentences.\n",
    "Context-free grammars, on the other hand, have many other applications: they could also be used to analyze DNA-sequences or to define the syntax of a programming language.\n",
    "Here's a metaphor: a salad fork (phrase structure grammar) is not all that different from any other fork (context-free grammar), the main distinction is that it's only meant to be used with salad.\n",
    "\n",
    "Alright, enough about terminology, let's get back to the productive stuff.\n",
    "We now have a very simple toy grammar with only three rules.\n",
    "Our last example in the previous exercise was quite a bit more complex.\n",
    "But it, too, can be used with `nltk.CFG.fromstring`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "toy_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | Aux NP V\n",
    "NP -> 'everybody' | 'nobody'\n",
    "VP -> 'snored'\n",
    "Aux -> 'did'\n",
    "V -> 'snore'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `productions` method to check that the grammar has indeed been correctly instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_grammar.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that `|` is just a shorthand for defining multiple right-hand sides, so the output of `productions` does indeed match the grammar we defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Okay, so now we have a toy grammar that's a bit more complex.\n",
    "A grammar by itself, though, isn't of much use.\n",
    "We only care about grammars to the extent that they allow us to talk about the structure of sentences.\n",
    "But a grammar by itself does not actually help us with finding the structure of a sentence.\n",
    "This task is handled by the **parser**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"everybody\", \"snored\"]\n",
    "parser = nltk.ChartParser(toy_grammar)\n",
    "for parse in parser.parse(sentence):\n",
    "    print(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above tells Python to build a chart parser from our toy grammar.\n",
    "This is essentially the CKY parser we encountered in class, with some minor modifications that do not matter here.\n",
    "The parser provides a method `parse` that computes **all** possible structures for a given sentence.\n",
    "\n",
    "The output of `parse` itself cannot be easily inspected with `print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parser.parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can convert it to a list and then look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(parser.parse(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little tricky to read, hmm?\n",
    "Even though it is hard to tell with all the brackets and parentheses, the list actually contains just a single element.\n",
    "Printing just this single element gives us the familiar output we saw earlier on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(parser.parse(sentence))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the difference in output?\n",
    "The nltk package defines a new class `Tree`, that is used to represent tree structures.\n",
    "A `Tree` object consists of a node and a list of the subtrees that the node is the mother of.\n",
    "But each subtree is itself a `Tree` object.\n",
    "This causes the somewhat convoluted output we saw with `list`.\n",
    "We can use indentation and linebreaks to make it a bit more digestible:\n",
    "\n",
    "```python\n",
    "[\n",
    " Tree('S',\n",
    "      [Tree('NP',\n",
    "            ['everybody']),\n",
    "       Tree('VP',\n",
    "            ['snorted'])\n",
    "      ]\n",
    "     )\n",
    "]\n",
    "```\n",
    "\n",
    "This is the actual structure of an nltk tree.\n",
    "Nobody likes clutter, though, so nltk uses some tricks to make sure that when a tree is the argument of `print`, it  is shown with the cleaner labeled bracketing format:\n",
    "\n",
    "```python\n",
    "(S (NP everybody) (VP snored))\n",
    "```\n",
    "\n",
    "As far as Python is concerned, however, that's just a formatting trick for increased readability.\n",
    "The actual tree structure is the more complicated one with `Tree`s containing `Tree`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more realistic example\n",
    "\n",
    "Let's move beyond our toy grammar and actually design a grammar that can handle some interesting cases of ambiguity in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | PN VP | Pro VP\n",
    "NP -> Det N | NP PP\n",
    "VP -> V NP | V PN | VP PP\n",
    "PP -> P NP | P PN\n",
    "Det -> 'a' | 'an' | 'the' | 'this' | 'my'\n",
    "N -> 'person' | 'hill' | 'telescope' | 'movie'\n",
    "Pro -> 'I' | 'you'\n",
    "PN -> 'Arnold'\n",
    "V -> 'saw' | 'watched'\n",
    "P -> 'in' | 'on' | 'with'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grammar above is in **Chomsky Normal Form** (CNF).\n",
    "This means that every rule is of the form `X -> Y Z` or `X -> 'terminal'`.\n",
    "In other words, every node in the tree has either exactly two non-terminals as daughters, or exactly one daughter that is a terminal.\n",
    "CNF does not change what strings are considered well-formed by the grammar, but it does change what the tree structures may look like.\n",
    "But since grammars in CNF are easier to handle for some parsers, that is often an acceptable trade-off.\n",
    "\n",
    "Let's see what our grammar produces for some (possibly) ambiguous sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_parses(sentence, grammar):\n",
    "    sentence = re.findall(r\"\\w+\", sentence)\n",
    "    parser = nltk.ChartParser(grammar)\n",
    "    for parse in parser.parse(sentence):\n",
    "        print(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_parses(\"I watched a movie with Arnold\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get two parses: one where me and Arnold watched a movie, and one where a movie with Arnold was watched by me.\n",
    "\n",
    "But what happens if there is no parse at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"Arnold movie watched a I with\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't get any output!\n",
    "That's because we're using a `for`-loop to print every item in the list of parses that the parser found.\n",
    "If there are no such parses at all, then the list is empty.\n",
    "So our loop reduces to `for parse in []`, which means that nothing at all happens.\n",
    "Let's modify our `print_parses` function so that we get an explicit notification if there is no parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_parses(sentence, grammar):\n",
    "    sentence = re.findall(r\"\\w+\", sentence)\n",
    "    parser = nltk.ChartParser(grammar)\n",
    "    empty = True  # let's assume there are no parses\n",
    "    for parse in parser.parse(sentence):\n",
    "        print(parse)\n",
    "        empty = False  # nope, found at least one parse\n",
    "    if empty:\n",
    "        print(\"no parses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_parses(\"I watched a movie with Arnold\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"Arnold movie watched a I with\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering why we didn't just use something like `if parser.parse(sentence) != []` or `if len(parser.parse(sentence)) > 0` to check if there are any parses.\n",
    "The answer is that `parser.parse(sentence)` doesn't return a list but a generator.\n",
    "Generators were covered in an expansion unit, so we won't go over them here.\n",
    "But the bottom line is that genreators are more ephemeral objects for which we cannot test emptiness in the usual ways.\n",
    "Hence the workaround with a boolean variable `empty` to keep track of whether any parses have been printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyways, let's try one more example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"I watched a film with Arnold\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, this didn't work.\n",
    "We got `ValueError: Grammar does not cover some of the input words: \"'film'\".`\n",
    "The way a CFG works, every lexical item must occur in some rewrite rule of the grammar.\n",
    "We can again use the `.productions` method to check for each word in the input what rule it occurred in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sentence = re.findall(r\"\\w+\", \"I watched a movie with Arnold\")\n",
    "for n in range(len(sentence)):\n",
    "    print(ambig_grammar.productions(rhs=sentence[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of `rhs=x` tells Python to only show us those rules whose right-hand side is `x`.\n",
    "So `rhs=sentence[n]` only shows the rules that have `sentence[n]` as their right-hand side.\n",
    "\n",
    "Okay, let's do one more example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"a movie with Arnold watched Arnold with Arnold\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sentence is not ambiguous according to the grammar because even though there is a rule `NP -> NP PP`, there is no `PN`-counterpart of the form `PN -> PN PP`.\n",
    "Hence proper names cannot be modified by PPs.\n",
    "This implies that *with Arnold* can only modify the VP in the example sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the chart\n",
    "\n",
    "As mentioned earlier, nltk's chart parser is a tuned version of the CKY algorithm.\n",
    "We can verify that by printing the initial and final chart used by the parser.\n",
    "The code for that is a bit complicated, so I've put it away in a separate file.\n",
    "Just run the cells below as usual and don't worry about the function definitions going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run chartprinter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chart(\"I watched a movie with Arnold\", ambig_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an excellent opportunity for you to test your own CKY parsing skills.\n",
    "The cells below contain an example grammar and some sentences.\n",
    "For each one, first draw your own chart, then run the code to see the actual output.\n",
    "Keep in mind that your chart should also contain the backpointers, which are not displayed in the output of `print_chart` as it would be too convoluted.\n",
    "Also, `print_chart` won't fill any cells beyond the first diagonal if there is no parse at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | PN VP | Pro VP\n",
    "NP -> Det NP | NP PP | A NP | A N | 'movies' | 'nobody'\n",
    "VP -> V NP | V PN | VP PP | 'slept' | 'snored'\n",
    "PP -> P NP | P PN\n",
    "Det -> 'a' | 'an' | 'the' | 'this' | 'my'\n",
    "N -> 'person' | 'hill' | 'telescope' | 'movie'\n",
    "Pro -> 'I' | 'you'\n",
    "PN -> 'Arnold'\n",
    "V -> 'saw' | 'watched'\n",
    "P -> 'in' | 'on' | 'with'\n",
    "A -> 'old' | 'cool' | 'young'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chart(\"I watched an old movie\", complex_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chart(\"I watched an old movie with Arnold\", complex_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chart(\"I watched a movie with young Arnold\", complex_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, ready for a real challenge?\n",
    "Time to parse some *police* sentences.\n",
    "For some reason that I haven't been able to determine, the charts do not display correctly in cases of lexical ambiguity, so you'll have to make do with a printout of the actual parses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | NP VPtop\n",
    "NP -> 'police' | NP RelS\n",
    "RelS -> NP VPrel\n",
    "VP -> V NP\n",
    "VPtop -> NP V\n",
    "VPrel -> 'police'\n",
    "V -> 'police'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"police police police\", police_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"police police police police\", police_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"police police police police police\", police_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"police police police police police police\", police_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful, the next one might make your head explode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parses(\"police police police police police police police\", police_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of potential parses explodes as sentences get longer.\n",
    "This is a basic fact of syntax: there are tons of ways to combine words, so a single string may have dozens of structures attached to it.\n",
    "Humans rarely notice this kind of ambiguity because we implicitly use meaning to quickly rule out implausible parses.\n",
    "For instance, if you hear somebody say \"I once shot an elephant in my pajamas\", you don't assume that the elephant was wearing the pajamas.\n",
    "Computers don't have access to this kind of world knowledge, and that's why parsing is a much harder task for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bullet point summary\n",
    "\n",
    "- Every sentence has an invisible tree structure.\n",
    "- The phrase structure of a sentence can be described by a context-free grammar:\n",
    "\n",
    "```python\n",
    "nltk.CFG.fromstring(\"\"\"\n",
    "X -> Y Z\n",
    "Y -> 'y'\n",
    "Z -> 'z'\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "- A grammar just defines the set of all possible structures in a language.\n",
    "  We need a parser to actually determine the structure(s) of a given sentence.\n",
    "  \n",
    "```python\n",
    "# instantiate parser from grammar\n",
    "some_parser = nltk.ChartParser(grammar)\n",
    "# compute all parses of a sentence\n",
    "parses = some_parser.parse(sentence)\n",
    "```\n",
    "\n",
    "- The `parse` method returns a generator (see the earlier expansion unit), **not** a list.\n",
    "  We can iterate over the generator with `for`, but we can't pick out individual elements, test emptyness, or calculate the length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
