{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementing prefix trees\n",
    "\n",
    "Alright, we are finally in a position to implement prefix trees, and we will contrast them with an approach based on tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Storing n-gram frequencies in a Counter\n",
    "\n",
    "With our modified definition of the `bigrams` function, a tokenized text is converted to a list of tuples, where each tuple is a bigram of the text.\n",
    "Since tuples are immutable and hence hashable, they can be used as keys.\n",
    "Hence we can feed this list of bigrams into a Counter without getting complaints about unhashable keys.\n",
    "We then convert the counts to frequencies, giving us a database of bigram frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def bigrams(text):\n",
    "    \"\"\"Convert a text (list of strings) to bigram-tuples.\"\"\"\n",
    "    return [tuple(text[n:n+2]) for n in range(len(text) - 1)]\n",
    "\n",
    "\n",
    "# compute counts\n",
    "bigram_counts = Counter(bigrams(brown.words()))\n",
    "\n",
    "# convert to frequencies\n",
    "total = sum(bigram_counts.values())\n",
    "for word in bigram_counts:\n",
    "    bigram_counts[word] /= total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can now easily determine the most common bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, the Brown corpus includes punctuation and does not normalize capitalization.\n",
    "Depending on our specific domain of application, we might want to normalize some of this, but we will ignore these issues here.\n",
    "\n",
    "We can also use our function for bigram predictions together with `counts`.\n",
    "We just have to adjust for the fact that the context is now checked against a slice of a tuple, rather than a list.\n",
    "Hence we first convert the context to a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def bigram_completions(word, context, counts):\n",
    "    \"\"\"Suugest word completion based on bigram frequencies.\"\"\"\n",
    "    # set of all compatible bigrams\n",
    "    comps = [comp for comp in counts\n",
    "             if comp[:-1] == tuple(context) and\n",
    "                comp[-1].startswith(word)]\n",
    "    # sort the bigram completions\n",
    "    ordered_ngrams = sorted(comps,\n",
    "                            key=counts.get,\n",
    "                            reverse=True)\n",
    "    # only keep last word of each bigram\n",
    "    return [ngram[-1] for ngram in ordered_ngrams]\n",
    "\n",
    "\n",
    "bigram_completions(\"test\", [\"a\"], bigram_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also look at the length of the counter to determine how many bigrams were generated from the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "len(bigram_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well, that's quite a lot, but it's much less than one might expect.\n",
    "Remember, just 10,000 distinct words already allow for 10 million distinct bigrams.\n",
    "This shows quite nicely that English puts tight restrictions on the order of words.\n",
    "It's anything but \"anything goes\".\n",
    "\n",
    "At any rate, let's now look at how the same counter can be represented as a prefix tree instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prefix trees as nested dictionaries\n",
    "\n",
    "The idea behind a prefix tree is share information across items.\n",
    "Suppose we have three trigrams `(\"the\", \"old\", \"man\")`, `(\"the\", \"old\", \"woman\")`, and `(\"the\", \"ugly\", \"man\")`, with the respective frequencies `0.1`, `0.2`, and `0.3`.\n",
    "With a prefix tree, we can conflate them into the representation below:\n",
    "\n",
    "```\n",
    "the\n",
    " |\n",
    " |--> old\n",
    " |     |\n",
    " |     |--> man: 0.1\n",
    " |     |\n",
    " |     |--> woman: 0.2\n",
    " |\n",
    " |--> ugly\n",
    "       |\n",
    "       |--> man: 0.3\n",
    "```\n",
    "\n",
    "We can replicate this structure with nested dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "trigram_tree = {\"the\": {\"old\": {\"man\": {\"_freq\": 0.1},\n",
    "                                \"woman\": {\"_freq\": 0.2}},\n",
    "                        \"ugly\": {\"man\": {\"_freq\": 0.3}}}}\n",
    "\n",
    "print(\"Whole tree:\\n\", trigram_tree)\n",
    "print()\n",
    "print(\"Trigrams starting with \\\"the\\\":\\n\",\n",
    "      trigram_tree.get(\"the\"))\n",
    "print()\n",
    "print(\"Trigrams starting with \\\"the old\\\":\\n\",\n",
    "      trigram_tree.get(\"the\").get(\"old\"))\n",
    "print()\n",
    "print(\"Subtree for \\\"the old woman\\\":\\n\",\n",
    "      trigram_tree.get(\"the\").get(\"old\").get(\"woman\"))\n",
    "print()\n",
    "print(\"Frequency for \\\"the old woman\\\":\\n\",\n",
    "      trigram_tree.get(\"the\").get(\"old\").get(\"woman\").get(\"freq\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that the key for frequency starts with an underscore.\n",
    "This is a trick to make sure that it won't be confused with some word `freq` that might occur in the corpus.\n",
    "\n",
    "Of course we do not want to build a prefix tree like this by hand, that would mean a lot of tedious and error-prone work.\n",
    "Instead, we will build it from an existing counter of n-gram frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def ngramcounter_to_prefixtree(counter):\n",
    "    \"\"\"Convert counter with n-gram frequencies to prefix tree.\"\"\"\n",
    "    # initialize prefix tree as empty dictionary\n",
    "    tree = {}\n",
    "    # iterate over key-value pairs in counter\n",
    "    for ngram, freq in counter.items(): \n",
    "        # start at root of prefix tree\n",
    "        current_subtree = tree\n",
    "        # then iterate over all words in ngram\n",
    "        for word in ngram:\n",
    "            if current_subtree.get(word):\n",
    "                current_subtree = current_subtree[word]\n",
    "            else:\n",
    "                current_subtree[word] = {}\n",
    "                current_subtree = current_subtree[word]\n",
    "        # at the end, add frequency to current_subtree\n",
    "        current_subtree[\"_freq\"] = freq\n",
    "    return tree\n",
    "\n",
    "\n",
    "# make sure you've run the first cell in this notebook,\n",
    "# otherwise bigram_counts won't be defined\n",
    "bigram_tree = ngramcounter_to_prefixtree(bigram_counts)\n",
    "\n",
    "print(bigram_tree.get(\"a\").get(\"test\").get(\"freq\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The code above might be a little confusing to you.\n",
    "It builds the tree in a top-down fashion, constantly resetting the value for `current_subtree` to a lower node while it moves along the n-gram.\n",
    "If the node does not exist, it creates a new subtree for it.\n",
    "The code below does the same thing, but with additional `print`-statements so you can see what it is going on.\n",
    "We also run it over a toy example, with the Brown bigram counts the output would take forever to print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def ngramcounter_to_prefixtree_with_print(counter):\n",
    "    \"\"\"Convert counter with n-gram frequencies to prefix tree.\"\"\"\n",
    "    # initialize prefix tree as empty dictionary\n",
    "    tree = {}\n",
    "    print(\"Starting up... tree is set to\", tree)\n",
    "    # iterate over key-value pairs in counter\n",
    "    for ngram, freq in counter.items(): \n",
    "        # start at root of prefix tree\n",
    "        print(\"\\n==========================\\n\")\n",
    "        print(f\"Working on \\\"{ngram}\\\" with frequency {freq}\")\n",
    "        current_subtree = tree\n",
    "        print(\"Setting current subtree to tree:\\n\", current_subtree)\n",
    "        # then iterate over all words in ngram\n",
    "        for word in ngram:\n",
    "            print(\"---\")\n",
    "            print(f\"Working on \\\"{word}\\\" with current subtree\\n\", current_subtree)\n",
    "            if current_subtree.get(word):\n",
    "                current_subtree = current_subtree[word]\n",
    "                print(f\"Found subtree for \\\"{word}\\\"\")\n",
    "            else:\n",
    "                print(f\"No subtree found for \\\"{word}\\\"\")\n",
    "                print(f\"Adding empty subtree under \\\"{word}\\\" in current subtree\")\n",
    "                current_subtree[word] = {}\n",
    "                print(\"Subtree has been expanded to\\n\", current_subtree)\n",
    "                current_subtree = current_subtree[word]\n",
    "            print(\"Reference of current_subtree variable is now\\n\", current_subtree)\n",
    "            print(f\"under \\\"{word}\\\" in prefix tree:\\n\", tree)\n",
    "        # at the end, add frequency to current_subtree\n",
    "        print(\"Reached end of n-gram, adding frequency\")\n",
    "        current_subtree[\"freq\"] = freq\n",
    "        print(f\"Prefix tree updated with frequency for \\\"{ngram}\\\"\")\n",
    "        print(tree)\n",
    "    return tree\n",
    "        \n",
    "\n",
    "example_counts = {(\"the\", \"old\", \"man\"): 0.1,\n",
    "                  (\"the\", \"old\", \"woman\"): 0.2,\n",
    "                  (\"the\", \"ugly\", \"man\"): 0.3}\n",
    "ngramcounter_to_prefixtree_with_print(example_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Alright, we have a function that converts an n-gram counter to an equivalent prefix tree.\n",
    "Note that the prefix tree conversion works for any counter, as long as its keys can be iterated over.\n",
    "For instance, we could just as well use the function above to convert a Counter with words counts to a prefix tree.\n",
    "In this case, each character of the word would be the root of another subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.corpus import words\n",
    "from pprint import pprint\n",
    "\n",
    "wordlist = words.words()\n",
    "counts = Counter(wordlist)\n",
    "tree = ngramcounter_to_prefixtree(counts)\n",
    "\n",
    "pprint(tree.get(\"w\").get(\"o\").get(\"r\").get(\"d\").get(\"s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The output above tells us that the word list contains at least the following:\n",
    "\n",
    "- wordsman (count: 1)\n",
    "- wordsmanship (count: 1)\n",
    "- wordsmith (count: 1)\n",
    "- wordspite (count: 1)\n",
    "- wordster (count: 1)\n",
    "\n",
    "Interestingly, words is apparently not in the list.\n",
    "We can check independently that this is indeed the case (which tells us that plurals are not stored separately in nltk's wordlist, apparently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "\"words\" in words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's compare that to the output if we use the Brown corpus as a basis instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from pprint import pprint\n",
    "\n",
    "wordlist = brown.words()\n",
    "counts = Counter(wordlist)\n",
    "tree = ngramcounter_to_prefixtree(counts)\n",
    "\n",
    "pprint(tree.get(\"w\").get(\"o\").get(\"r\").get(\"d\").get(\"s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Apparently, the Brown corpus contains 269 instances of *words*, but not a single instance of the completions in the word list.\n",
    "Let's check that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "wordlist = set(brown.words())\n",
    "print(\"words\" in wordlist)\n",
    "for suffix in [\"man\", \"manship\", \"mith\", \"pite\", \"ter\"]:\n",
    "    print(\"words\" + suffix in wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Alright, it looks like our prefix tree conversion does indeed work as desired.\n",
    "We have successfully created a new data structure for ourselves, one that is implemented in terms of nested dictionaries.\n",
    "The task is far from done, though.\n",
    "We still need at least two helper functions that make the data structure easy to work with:\n",
    "\n",
    "- an update mechanism for adding new elements to the tree\n",
    "- a search function for easily retrieving items (the chains of `.get` calls isn't exactly nice)\n",
    "\n",
    "But this is left as an exercise to the reader (i.e. you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bullet-point summary\n",
    "\n",
    "- Prefix trees can be implemented as nested dictionaries.\n",
    "  There are more efficient options, but those are a lot more difficult to handle.\n",
    "  If you want a production-level implementation, check out the `pygtrie` package.\n",
    "  \n",
    "- The conversion builds the prefix tree in a top-down fashion, adding new subtrees (i.e. dictionaries) as necessary.\n",
    "  Make sure you understand 100% of the code for this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}